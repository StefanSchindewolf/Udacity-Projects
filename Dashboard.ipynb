{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import configparser\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read configuration file and connect to database\n",
    "from etl import create_client\n",
    "from sql_queries import analytics_tables, staging_tables\n",
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dwh.cfg')\n",
    "KEY                    = config.get('AWS','KEY')\n",
    "SECRET                 = config.get('AWS','SECRET')\n",
    "DWH_DB                 = config.get(\"DWH\",\"DWH_DB\")\n",
    "DWH_DB_USER            = config.get(\"DWH\",\"DWH_DB_USER\")\n",
    "DWH_DB_PASSWORD        = config.get(\"DWH\",\"DWH_DB_PASSWORD\")\n",
    "DWH_PORT               = config.get(\"DWH\",\"DWH_PORT\")\n",
    "DWH_CLUSTER_IDENTIFIER = config.get(\"DWH\",\"DWH_CLUSTER_IDENTIFIER\")\n",
    "redshift_client = create_client(KEY, SECRET, 'redshift')\n",
    "myClusterProps = redshift_client.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "DWH_ENDPOINT = myClusterProps['Endpoint']['Address']\n",
    "\n",
    "conn_string=\"postgresql://{}:{}@{}:{}/{}\".format(DWH_DB_USER, DWH_DB_PASSWORD, DWH_ENDPOINT, DWH_PORT,DWH_DB)\n",
    "%sql $conn_string\n",
    "%sql SET search_path TO dist;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 1. Check if entries were created in each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Check if each table has enrtries\n",
    "entries = []\n",
    "\n",
    "for t in analytics_tables:\n",
    "    result = %sql select count(*) from $t\n",
    "    entries.append(result[0][0])\n",
    "\n",
    "entries_df = pd.DataFrame({'entries': entries}, index=analytics_tables)\n",
    "entries_df.plot.bar()\n",
    "entries = []\n",
    "\n",
    "for t in staging_tables:\n",
    "    result = %sql select count(*) from $t\n",
    "    entries.append(result[0][0])\n",
    "\n",
    "entries_df = pd.DataFrame({'entries': entries}, index=staging_tables)\n",
    "entries_df.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 2. Check for duplicate songs from the same artists in staging_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Check for duplicate titles from an artist\n",
    "%sql select artist_name, title, count(title) from staging_songs group by artist_name, title having count(*) > 1 order by count(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 3. Check for missing artist locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Check of missing data in songs files\n",
    "all_artists = %sql select count(*) from artists\n",
    "missing_locations = %sql select count(*) from staging_songs where artist_location is null\n",
    "all_artists = all_artists[0][0]\n",
    "missing_locations = missing_locations[0][0]\n",
    "result_df = pd.DataFrame({'entries': [all_artists, missing_locations]}, index=['all artists', 'artists with missing locations'])\n",
    "result_df.plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4. Check for NextSong actions that cannot be matched to songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Check for missing data in NextSong actions that prevent it from being matched fully\n",
    "all_events = %sql select count(*) from staging_events\n",
    "all_events = all_events[0][0]\n",
    "%sql create temp table next_songs as select * from staging_events where page like 'NextSong'\n",
    "next_song_actions = %sql select count(*) from next_songs\n",
    "next_song_actions = next_song_actions[0][0]\n",
    "title_match = %sql select count(*) from next_songs inner join staging_songs on staging_songs.title like next_songs.song\n",
    "title_match = title_match[0][0]\n",
    "\n",
    "results = pd.DataFrame({'entries': [all_events, next_song_actions, title_match]}, index=['All events', 'All NextSong actions', 'NextSong Actions with matching song title'])\n",
    "results.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 5. Check for runtimes of each ETL step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Check SQL runtimes for loading and transforming\n",
    "%sql SET search_path TO dist;\n",
    "rt_df = %sql select * from dashboard\n",
    "rt_df = rt_df.DataFrame()\n",
    "rt_df.plot(kind='bar', title='Runtimes of ETL steps in seconds', legend=True, label=rt_df.step.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 6. Check the Top 10 songs in table songplays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "top10_df = %sql select songs.title, count(*) as played from songplays join songs on songs.song_id like songplays.song_id join artists on artists.artist_id like songs.artist_id group by songs.title order by played desc limit 10\n",
    "top10_df = top10_df.DataFrame()\n",
    "top10_df = top10_df.set_index('title')\n",
    "top10_df = top10_df.sort_values(by='played')\n",
    "top10_df.plot.barh(sort_columns=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
