{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace\n",
      "['/home/workspace/event_data/2018-11-30-events.csv', '/home/workspace/event_data/2018-11-23-events.csv', '/home/workspace/event_data/2018-11-22-events.csv', '/home/workspace/event_data/2018-11-29-events.csv', '/home/workspace/event_data/2018-11-11-events.csv', '/home/workspace/event_data/2018-11-14-events.csv', '/home/workspace/event_data/2018-11-20-events.csv', '/home/workspace/event_data/2018-11-15-events.csv', '/home/workspace/event_data/2018-11-05-events.csv', '/home/workspace/event_data/2018-11-28-events.csv', '/home/workspace/event_data/2018-11-25-events.csv', '/home/workspace/event_data/2018-11-16-events.csv', '/home/workspace/event_data/2018-11-18-events.csv', '/home/workspace/event_data/2018-11-24-events.csv', '/home/workspace/event_data/2018-11-04-events.csv', '/home/workspace/event_data/2018-11-19-events.csv', '/home/workspace/event_data/2018-11-26-events.csv', '/home/workspace/event_data/2018-11-12-events.csv', '/home/workspace/event_data/2018-11-27-events.csv', '/home/workspace/event_data/2018-11-06-events.csv', '/home/workspace/event_data/2018-11-09-events.csv', '/home/workspace/event_data/2018-11-03-events.csv', '/home/workspace/event_data/2018-11-21-events.csv', '/home/workspace/event_data/2018-11-07-events.csv', '/home/workspace/event_data/2018-11-01-events.csv', '/home/workspace/event_data/2018-11-13-events.csv', '/home/workspace/event_data/2018-11-17-events.csv', '/home/workspace/event_data/2018-11-08-events.csv', '/home/workspace/event_data/2018-11-10-events.csv', '/home/workspace/event_data/2018-11-02-events.csv']\n"
     ]
    }
   ],
   "source": [
    "# Checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Collect files from directory and remote hidden files and folders from the list\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    # Remove Unix hidden files starting with \".\"\n",
    "    files = [file for file in files if not file.startswith(\".\")]\n",
    "    # Remove UNIX hidden directories\n",
    "    dirs[:] = [d for d in dirs if not d[0] == '.']\n",
    "    # Add files to file path list if their exstension is .csv or .CSV\n",
    "    file_path_list = [file for file in files if file.endswith(\".csv\") or file.endswith(\".CSV\")]\n",
    "\n",
    "# Join the file path and roots with the subdirectories using glob\n",
    "file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "#print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Complete the Apache Cassandra coding portion of your project. \n",
    "\n",
    "## Now you are ready to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Cassandra cluster and keyspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should make a connection to a Cassandra instance your local machine \n",
    "# (127.0.0.1)\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "\n",
    "# To establish connection and begin executing queries, need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7fcd25c2c518>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our keyspace is named \"events\"\n",
    "# Should it exist already then drop it\n",
    "stm = \"DROP KEYSPACE IF EXISTS events\"\n",
    "session.execute(stm)\n",
    "\n",
    "# Now create the keyspace\n",
    "stm = \"CREATE KEYSPACE events WITH replication = {'class': 'SimpleStrategy', 'replication_factor' : 1};\"\n",
    "session.execute(stm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7fcd4d5de400>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set our current keyspace to \"events\", which we created above\n",
    "session.execute(\"USE events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table preparation\n",
    "- Primary key is sessionId and itemInSessions which uniquely identifies played song, artist and length\n",
    "- Clustering is not required\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define drop and create statement\n",
    "drop1 = \"DROP TABLE artistTitle_by_sessiondata\"\n",
    "\n",
    "# Define create statement\n",
    "create1 = \"CREATE TABLE IF NOT EXISTS artistTitle_by_sessiondata (sessionId int, itemInSession int, artist text, song_title text, song_length float, PRIMARY KEY (sessionId, itemInSession))\"\n",
    "\n",
    "# Try to create the table and if it exists reset the table\n",
    "try:\n",
    "    session.execute(create1)\n",
    "except:\n",
    "    session.execute(drop1)\n",
    "    session.execute(create1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare source file where we read the data from\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "# Open file and read content starting from line 2 (first line contains header)\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    # Insert data from each line into the table\n",
    "    for line in csvreader:\n",
    "        # Prepare INSERT statement\n",
    "        query = \"INSERT INTO artistTitle_by_sessiondata (sessionId, itemInSession, artist, song_title, song_length) VALUES\"\n",
    "        query = query + \"(%s, %s, %s, %s, %s)\"\n",
    "        # Run INSERT with selected colums from csv file\n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], float(line[5]), ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Control\n",
    "- Expected returned fields are artist, song_title and song_length\n",
    "- Filter table for sessionId 338 and itemInSession 4 using WHERE clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song_title</th>\n",
       "      <th>song_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Faithless</td>\n",
       "      <td>Music Matters (Mark Knight Dub)</td>\n",
       "      <td>495.307312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      artist                       song_title  song_length\n",
       "0  Faithless  Music Matters (Mark Knight Dub)   495.307312"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First define SELECT statement\n",
    "query1 = \"SELECT artist, song_title, song_length FROM artistTitle_by_sessiondata WHERE sessionId = 338 and itemInSession = 4;\"\n",
    "\n",
    "# Execute statement and print results\n",
    "df1 = pd.DataFrame(list(session.execute(query1)))\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table preparation\n",
    "- Primary key is sessionId and userId since those uniquely identify the songs which a specific user listened to in a session\n",
    "- Clustering key is itemInSession so that we can apply ORDER BY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define drop and create statement\n",
    "drop2 = \"DROP TABLE artistTitle_by_userSession\"\n",
    "# Define create statement\n",
    "create2 = \"CREATE TABLE IF NOT EXISTS artistTitle_by_userSession (sessionId int, userId int, itemInSessions int, artist text, song_title text, user_first text, user_last text, PRIMARY KEY ((sessionId, userId), itemInSessions))\"\n",
    "\n",
    "# Create table or drop and recreate\n",
    "try:\n",
    "    session.execute(create2)\n",
    "except:\n",
    "    session.execute(drop2)\n",
    "    session.execute(create2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data from file\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    # Iterate each line and fill INSERT statement with data\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO artistTitle_by_userSession (sessionId, userId, itemInSessions, artist, song_title, user_first, user_last) VALUES\"\n",
    "        query = query + \"(%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line[8]), int(line[10]), int(line[3]), str(line[0]), str(line[9]), str(line[1]), str(line[4]), ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result control   \n",
    "- Expected returned fields are artist, song_title, user_first and user_last\n",
    "- Filter table for userId 10 and sessionId 182 using WHERE clause\n",
    "- Order results by itemInSessions using ORDER BY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song_title</th>\n",
       "      <th>user_first</th>\n",
       "      <th>user_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Down To The Bone</td>\n",
       "      <td>Keep On Keepin' On</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Three Drives</td>\n",
       "      <td>Greece 2000</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sebastien Tellier</td>\n",
       "      <td>Kilometer</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lonnie Gordon</td>\n",
       "      <td>Catch You Baby (Steve Pitron &amp; Max Sanna Radio...</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist                                         song_title  \\\n",
       "0   Down To The Bone                                 Keep On Keepin' On   \n",
       "1       Three Drives                                        Greece 2000   \n",
       "2  Sebastien Tellier                                          Kilometer   \n",
       "3      Lonnie Gordon  Catch You Baby (Steve Pitron & Max Sanna Radio...   \n",
       "\n",
       "  user_first user_last  \n",
       "0     Sylvie      Cruz  \n",
       "1     Sylvie      Cruz  \n",
       "2     Sylvie      Cruz  \n",
       "3     Sylvie      Cruz  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First define SELECT statement\n",
    "query2 = \"SELECT artist, song_title, user_first, user_last FROM artistTitle_by_userSession WHERE sessionId = 182 and userId = 10 ORDER BY itemInSessions;\"\n",
    "\n",
    "# Execute query and store results in \"rows\" list, then iterate the list to print each line\n",
    "df2 = pd.DataFrame(list(session.execute(query2)))\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Give first and last names of users who listened to a specific title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table preparation\n",
    "- Primary key is composed of song_title and userId\n",
    "- So we can select all rows with song_title = 'xyz' and then group the data by userId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define drop statement\n",
    "drop3 = \"DROP TABLE user_by_title\"\n",
    "# Create statement\n",
    "#create3 = \"CREATE TABLE IF NOT EXISTS user_by_title (song_title text, sessionId int, itemInSessions int, artist text, song_length float, userId int, user_first text, user_last text, PRIMARY KEY ((song_title), sessionId, itemInSessions))\"\n",
    "create3 = \"CREATE TABLE IF NOT EXISTS user_by_title (song_title text, sessionId int, itemInSessions int, artist text, song_length float, userId int, user_first text, user_last text, PRIMARY KEY ((song_title), userId))\"\n",
    "\n",
    "# Create Table or drop and create again if exists\n",
    "try:\n",
    "    session.execute(create3)\n",
    "except:\n",
    "    session.execute(drop3)\n",
    "    session.execute(create3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Upload   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    # Take required fields from each line and use as input for INSERT statement\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO user_by_title (song_title, sessionId, itemInSessions, artist, song_length, userId, user_first, user_last) VALUES\"\n",
    "        query = query + \"(%s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (str(line[9]), int(line[8]), int(line[3]), str(line[0]), float(line[5]), int(line[10]), str(line[1]), str(line[4]), ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Control\n",
    "- Expected query results are user_first and user_last\n",
    "- Filter table for song title using WHERE clause\n",
    "- Group by userId without any aggregate will lead to only the first result of each userId being selected and returned (no duplicates per user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_first</th>\n",
       "      <th>user_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chloe</td>\n",
       "      <td>Cuevas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emily</td>\n",
       "      <td>Benson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Colm</td>\n",
       "      <td>Santana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kate</td>\n",
       "      <td>Harrell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_first user_last\n",
       "0      Chloe    Cuevas\n",
       "1      Emily    Benson\n",
       "2       Colm   Santana\n",
       "3       Kate   Harrell"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare SELECT statement\n",
    "#title = \"All Hands Against His Own\"\n",
    "title = \"Fix You\"\n",
    "query3 = \"SELECT user_first, user_last FROM user_by_title WHERE song_title = %s GROUP BY userId;\"\n",
    "\n",
    "# Execute SELECT and print query result\n",
    "df3 = pd.DataFrame(list(session.execute(query3, [title])))\n",
    "df3.head()          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop tables\n",
    "We have already prepared the drop statements above to reset tables with each notebook run\n",
    "So we simply rerun the drop statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7fcd4d639898>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(drop1)\n",
    "session.execute(drop2)\n",
    "session.execute(drop3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connectionÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
